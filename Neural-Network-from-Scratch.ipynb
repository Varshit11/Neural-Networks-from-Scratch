{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will implement neural network from scratch..\n",
    "# importing the libraries..\n",
    "import numpy as np\n",
    "import pandas as pd # for importing data\n",
    "\n",
    "# num_layers = total no. of layers in neural network.\n",
    "# num_neurons = it is an list which contains the no. of neurons in each layer. Its length is one more than num_layers..\n",
    "# num_features = it is the no. of features in the training data\n",
    "# m = it is the no. of training examples.\n",
    "# currenty working on binary classification task...later will add multi label and regression in our network..\n",
    "# no batch norm used now and no batch gradient descent is used now.\n",
    "class Neuralnetwork:\n",
    "    def __init__(self, num_layers, num_neurons, num_features, m, lr, num_epochs):\n",
    "        self.num_layers = num_layers\n",
    "        self.num_neurons = num_neurons\n",
    "        self.Nx = num_features\n",
    "        self.m = m\n",
    "        self.lr = lr\n",
    "        self.num_epochs = num_epochs\n",
    "        self.accuracy = 0\n",
    "        self.train_pred = []\n",
    "        self.W = [np.random.randn(self.num_neurons[0], 1)]\n",
    "        self.dW = [np.random.randn(self.num_neurons[0], 1)]\n",
    "        self.J = 0\n",
    "        self.b = [np.random.randn(self.num_neurons[0], 1)]\n",
    "        self.db = [np.random.randn(self.num_neurons[0], 1)]\n",
    "        self.Z = [np.random.randn(self.num_neurons[0], 1)]\n",
    "        self.A = [np.random.randn(self.num_neurons[0], self.m)]\n",
    "        self.dZ =  [np.random.randn(self.num_neurons[0], 1)]\n",
    "        self.dA = [np.random.randn(self.num_neurons[0], self.m)]\n",
    "\n",
    "        for i in range(len(self.num_neurons)-1):\n",
    "            temp_w = np.random.randn(self.num_neurons[i+1], self.num_neurons[i])\n",
    "            temp_b = np.zeros([self.num_neurons[i+1], 1])\n",
    "            self.W.append(temp_w)\n",
    "            self.b.append(temp_b)\n",
    "            self.dW.append(temp_w)\n",
    "            self.db.append(temp_b)\n",
    "            self.Z.append(np.random.randn(self.num_neurons[i+1], self.m))\n",
    "            self.dZ.append(np.random.randn(self.num_neurons[i+1], self.m))\n",
    "            self.A.append(np.random.randn(self.num_neurons[i+1], self.m))\n",
    "            self.dA.append(np.random.randn(self.num_neurons[i+1], self.m))\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        return(1/(1+np.exp(-z)))\n",
    "    \n",
    "    def derivative_sigmoid(self, z):\n",
    "        return(self.sigmoid(z)*(1-self.sigmoid(z)))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.A[0] = X\n",
    "        for i in range(1, len(self.num_neurons)):\n",
    "            self.Z[i] = np.dot(self.W[i], self.A[i-1]) + self.b[i]\n",
    "            self.A[i] = self.sigmoid(self.Z[i])\n",
    "    \n",
    "    def backprop(self, Y):\n",
    "        self.dZ[len(self.num_neurons)-1] = self.A[len(self.num_neurons)-1] - Y\n",
    "        self.dW[len(self.num_neurons)-1] = np.dot(self.dZ[len(self.num_neurons)-1], self.A[len(self.num_neurons)-2].T)/self.m\n",
    "        self.db[len(self.num_neurons)-1] = np.sum(self.dZ[len(self.num_neurons)-1], axis = 1, keepdims = True)/self.m\n",
    "        self.W[len(self.num_neurons)-1] -= self.lr*self.dW[len(self.num_neurons)-1]\n",
    "        self.b[len(self.num_neurons)-1] -= self.lr*self.db[len(self.num_neurons)-1]\n",
    "        for i in range(len(self.num_neurons)-2, 0, -1):\n",
    "            self.dZ[i] = np.multiply(np.dot(self.dW[i+1].T, self.dZ[i+1]),self.derivative_sigmoid(self.Z[i]))\n",
    "            self.dW[i] = np.dot(self.dZ[i], self.A[i-1].T)/self.m\n",
    "            self.db[i] = np.sum(self.dZ[i], axis = 1, keepdims=True)/self.m\n",
    "            self.W[i] -= self.lr*self.dW[i]\n",
    "            self.b[i] -= self.lr*self.db[i]\n",
    "    \n",
    "    def find_loss(self, Y):\n",
    "        self.J = np.sum(-1*Y*np.log(self.A[len(self.num_neurons)-1]) -1*(1-Y)*np.log(1 - self.A[len(self.num_neurons)-1]))/self.m\n",
    "        count = 0\n",
    "        for i in range(self.m):\n",
    "            if self.A[len(self.num_neurons)-1][0][i] <= 0.5:\n",
    "                a = 0\n",
    "            else:\n",
    "                a = 1\n",
    "            if a == Y[i]:\n",
    "                count+=1\n",
    "        self.accuracy = count/self.m\n",
    "        print(\"Accuracy = {}, Loss = {}\".format(self.accuracy, self.J))\n",
    "\n",
    "            \n",
    "    def fit(self, X, Y):\n",
    "        for i in range(self.num_epochs):\n",
    "            self.forward(X);\n",
    "            self.backprop(Y);\n",
    "            self.find_loss(Y);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/User/Pictures/Neural-network-from-scratch/IRIS.csv\")\n",
    "X = data.iloc[:, 0:4]\n",
    "Y = data.iloc[:, 4]\n",
    "X.head()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Neuralnetwork(3,[4,32, 64, 32, 1],4,100, 0.001, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.5, Loss = 0.8277701393891383\n",
      "Accuracy = 0.5, Loss = 0.8264488580265728\n",
      "Accuracy = 0.5, Loss = 0.8251344341464741\n",
      "Accuracy = 0.5, Loss = 0.823826848095397\n",
      "Accuracy = 0.5, Loss = 0.8225260800855768\n",
      "Accuracy = 0.5, Loss = 0.8212321101968914\n",
      "Accuracy = 0.5, Loss = 0.8199449183788242\n",
      "Accuracy = 0.5, Loss = 0.8186644844524334\n",
      "Accuracy = 0.5, Loss = 0.8173907881123251\n",
      "Accuracy = 0.5, Loss = 0.8161238089286335\n",
      "Accuracy = 0.5, Loss = 0.8148635263490008\n",
      "Accuracy = 0.5, Loss = 0.8136099197005657\n",
      "Accuracy = 0.5, Loss = 0.8123629681919498\n",
      "Accuracy = 0.5, Loss = 0.8111226509152516\n",
      "Accuracy = 0.5, Loss = 0.8098889468480394\n",
      "Accuracy = 0.5, Loss = 0.8086618348553481\n",
      "Accuracy = 0.5, Loss = 0.8074412936916778\n",
      "Accuracy = 0.5, Loss = 0.8062273020029929\n",
      "Accuracy = 0.5, Loss = 0.8050198383287216\n",
      "Accuracy = 0.5, Loss = 0.8038188811037584\n",
      "Accuracy = 0.5, Loss = 0.802624408660464\n",
      "Accuracy = 0.5, Loss = 0.8014363992306673\n",
      "Accuracy = 0.5, Loss = 0.8002548309476648\n",
      "Accuracy = 0.5, Loss = 0.7990796818482222\n",
      "Accuracy = 0.5, Loss = 0.7979109298745716\n",
      "Accuracy = 0.5, Loss = 0.7967485528764082\n",
      "Accuracy = 0.5, Loss = 0.7955925286128875\n",
      "Accuracy = 0.5, Loss = 0.7944428347546166\n",
      "Accuracy = 0.5, Loss = 0.7932994488856441\n",
      "Accuracy = 0.5, Loss = 0.7921623485054511\n",
      "Accuracy = 0.5, Loss = 0.7910315110309304\n",
      "Accuracy = 0.5, Loss = 0.7899069137983724\n",
      "Accuracy = 0.5, Loss = 0.7887885340654397\n",
      "Accuracy = 0.5, Loss = 0.787676349013139\n",
      "Accuracy = 0.5, Loss = 0.7865703357477922\n",
      "Accuracy = 0.5, Loss = 0.7854704713029979\n",
      "Accuracy = 0.5, Loss = 0.7843767326415905\n",
      "Accuracy = 0.5, Loss = 0.7832890966575944\n",
      "Accuracy = 0.5, Loss = 0.7822075401781702\n",
      "Accuracy = 0.5, Loss = 0.7811320399655566\n",
      "Accuracy = 0.5, Loss = 0.7800625727190059\n",
      "Accuracy = 0.5, Loss = 0.7789991150767126\n",
      "Accuracy = 0.5, Loss = 0.7779416436177358\n",
      "Accuracy = 0.5, Loss = 0.7768901348639123\n",
      "Accuracy = 0.5, Loss = 0.775844565281767\n",
      "Accuracy = 0.5, Loss = 0.7748049112844093\n",
      "Accuracy = 0.5, Loss = 0.7737711492334286\n",
      "Accuracy = 0.5, Loss = 0.7727432554407742\n",
      "Accuracy = 0.5, Loss = 0.7717212061706341\n",
      "Accuracy = 0.5, Loss = 0.7707049776413006\n",
      "Accuracy = 0.5, Loss = 0.7696945460270274\n",
      "Accuracy = 0.5, Loss = 0.7686898874598788\n",
      "Accuracy = 0.5, Loss = 0.7676909780315693\n",
      "Accuracy = 0.5, Loss = 0.766697793795294\n",
      "Accuracy = 0.5, Loss = 0.765710310767547\n",
      "Accuracy = 0.5, Loss = 0.7647285049299327\n",
      "Accuracy = 0.5, Loss = 0.7637523522309647\n",
      "Accuracy = 0.5, Loss = 0.762781828587855\n",
      "Accuracy = 0.5, Loss = 0.7618169098882939\n",
      "Accuracy = 0.5, Loss = 0.7608575719922162\n",
      "Accuracy = 0.5, Loss = 0.7599037907335588\n",
      "Accuracy = 0.5, Loss = 0.7589555419220056\n",
      "Accuracy = 0.5, Loss = 0.7580128013447218\n",
      "Accuracy = 0.5, Loss = 0.7570755447680753\n",
      "Accuracy = 0.5, Loss = 0.7561437479393496\n",
      "Accuracy = 0.5, Loss = 0.7552173865884402\n",
      "Accuracy = 0.5, Loss = 0.7542964364295414\n",
      "Accuracy = 0.5, Loss = 0.7533808731628223\n",
      "Accuracy = 0.5, Loss = 0.7524706724760861\n",
      "Accuracy = 0.5, Loss = 0.7515658100464213\n",
      "Accuracy = 0.5, Loss = 0.7506662615418364\n",
      "Accuracy = 0.5, Loss = 0.7497720026228849\n",
      "Accuracy = 0.5, Loss = 0.7488830089442751\n",
      "Accuracy = 0.5, Loss = 0.7479992561564665\n",
      "Accuracy = 0.5, Loss = 0.7471207199072564\n",
      "Accuracy = 0.5, Loss = 0.7462473758433472\n",
      "Accuracy = 0.5, Loss = 0.7453791996119066\n",
      "Accuracy = 0.5, Loss = 0.7445161668621091\n",
      "Accuracy = 0.5, Loss = 0.7436582532466655\n",
      "Accuracy = 0.5, Loss = 0.7428054344233398\n",
      "Accuracy = 0.5, Loss = 0.7419576860564505\n",
      "Accuracy = 0.5, Loss = 0.7411149838183584\n",
      "Accuracy = 0.5, Loss = 0.7402773033909397\n",
      "Accuracy = 0.5, Loss = 0.7394446204670451\n",
      "Accuracy = 0.5, Loss = 0.7386169107519462\n",
      "Accuracy = 0.5, Loss = 0.7377941499647648\n",
      "Accuracy = 0.5, Loss = 0.7369763138398885\n",
      "Accuracy = 0.5, Loss = 0.7361633781283736\n",
      "Accuracy = 0.5, Loss = 0.735355318599331\n",
      "Accuracy = 0.5, Loss = 0.7345521110412976\n",
      "Accuracy = 0.5, Loss = 0.733753731263596\n",
      "Accuracy = 0.5, Loss = 0.7329601550976738\n",
      "Accuracy = 0.5, Loss = 0.7321713583984341\n",
      "Accuracy = 0.5, Loss = 0.7313873170455463\n",
      "Accuracy = 0.5, Loss = 0.730608006944745\n",
      "Accuracy = 0.5, Loss = 0.7298334040291126\n",
      "Accuracy = 0.5, Loss = 0.7290634842603461\n",
      "Accuracy = 0.5, Loss = 0.728298223630011\n",
      "Accuracy = 0.5, Loss = 0.7275375981607789\n",
      "Accuracy = 0.5, Loss = 0.7267815839076478\n",
      "Accuracy = 0.5, Loss = 0.7260301569591523\n",
      "Accuracy = 0.5, Loss = 0.7252832934385538\n",
      "Accuracy = 0.5, Loss = 0.7245409695050182\n",
      "Accuracy = 0.5, Loss = 0.7238031613547778\n",
      "Accuracy = 0.5, Loss = 0.7230698452222769\n",
      "Accuracy = 0.5, Loss = 0.7223409973813049\n",
      "Accuracy = 0.5, Loss = 0.7216165941461103\n",
      "Accuracy = 0.5, Loss = 0.7208966118725038\n",
      "Accuracy = 0.5, Loss = 0.7201810269589424\n",
      "Accuracy = 0.5, Loss = 0.7194698158476018\n",
      "Accuracy = 0.5, Loss = 0.7187629550254296\n",
      "Accuracy = 0.5, Loss = 0.7180604210251879\n",
      "Accuracy = 0.5, Loss = 0.7173621904264774\n",
      "Accuracy = 0.5, Loss = 0.7166682398567461\n",
      "Accuracy = 0.5, Loss = 0.7159785459922885\n",
      "Accuracy = 0.5, Loss = 0.7152930855592196\n",
      "Accuracy = 0.5, Loss = 0.7146118353344458\n",
      "Accuracy = 0.5, Loss = 0.7139347721466105\n",
      "Accuracy = 0.5, Loss = 0.7132618728770302\n",
      "Accuracy = 0.5, Loss = 0.7125931144606166\n",
      "Accuracy = 0.5, Loss = 0.7119284738867785\n",
      "Accuracy = 0.5, Loss = 0.7112679282003144\n",
      "Accuracy = 0.5, Loss = 0.7106114545022878\n",
      "Accuracy = 0.5, Loss = 0.7099590299508871\n",
      "Accuracy = 0.5, Loss = 0.7093106317622729\n",
      "Accuracy = 0.5, Loss = 0.7086662372114084\n",
      "Accuracy = 0.5, Loss = 0.7080258236328766\n",
      "Accuracy = 0.5, Loss = 0.7073893684216835\n",
      "Accuracy = 0.5, Loss = 0.7067568490340459\n",
      "Accuracy = 0.5, Loss = 0.7061282429881629\n",
      "Accuracy = 0.5, Loss = 0.7055035278649789\n",
      "Accuracy = 0.5, Loss = 0.7048826813089261\n",
      "Accuracy = 0.5, Loss = 0.7042656810286542\n",
      "Accuracy = 0.5, Loss = 0.70365250479775\n",
      "Accuracy = 0.5, Loss = 0.7030431304554382\n",
      "Accuracy = 0.5, Loss = 0.7024375359072699\n",
      "Accuracy = 0.5, Loss = 0.7018356991257988\n",
      "Accuracy = 0.5, Loss = 0.7012375981512404\n",
      "Accuracy = 0.5, Loss = 0.7006432110921191\n",
      "Accuracy = 0.5, Loss = 0.7000525161259046\n",
      "Accuracy = 0.5, Loss = 0.6994654914996278\n",
      "Accuracy = 0.5, Loss = 0.6988821155304896\n",
      "Accuracy = 0.5, Loss = 0.698302366606454\n",
      "Accuracy = 0.5, Loss = 0.6977262231868266\n",
      "Accuracy = 0.5, Loss = 0.6971536638028217\n",
      "Accuracy = 0.5, Loss = 0.696584667058116\n",
      "Accuracy = 0.5, Loss = 0.6960192116293876\n",
      "Accuracy = 0.5, Loss = 0.6954572762668455\n",
      "Accuracy = 0.5, Loss = 0.6948988397947405\n",
      "Accuracy = 0.5, Loss = 0.6943438811118713\n",
      "Accuracy = 0.5, Loss = 0.6937923791920696\n",
      "Accuracy = 0.5, Loss = 0.6932443130846789\n",
      "Accuracy = 0.5, Loss = 0.6926996619150166\n",
      "Accuracy = 0.5, Loss = 0.6921584048848282\n",
      "Accuracy = 0.5, Loss = 0.6916205212727224\n",
      "Accuracy = 0.5, Loss = 0.6910859904346028\n",
      "Accuracy = 0.5, Loss = 0.6905547918040804\n",
      "Accuracy = 0.5, Loss = 0.6900269048928744\n",
      "Accuracy = 0.5, Loss = 0.6895023092912088\n",
      "Accuracy = 0.5, Loss = 0.6889809846681879\n",
      "Accuracy = 0.5, Loss = 0.688462910772164\n",
      "Accuracy = 0.5, Loss = 0.6879480674310947\n",
      "Accuracy = 0.5, Loss = 0.6874364345528876\n",
      "Accuracy = 0.5, Loss = 0.6869279921257331\n",
      "Accuracy = 0.5, Loss = 0.6864227202184258\n",
      "Accuracy = 0.5, Loss = 0.6859205989806774\n",
      "Accuracy = 0.5, Loss = 0.6854216086434144\n",
      "Accuracy = 0.5, Loss = 0.6849257295190693\n",
      "Accuracy = 0.5, Loss = 0.6844329420018558\n",
      "Accuracy = 0.5, Loss = 0.6839432265680395\n",
      "Accuracy = 0.5, Loss = 0.6834565637761929\n",
      "Accuracy = 0.5, Loss = 0.6829729342674423\n",
      "Accuracy = 0.5, Loss = 0.6824923187657034\n",
      "Accuracy = 0.5, Loss = 0.6820146980779077\n",
      "Accuracy = 0.5, Loss = 0.6815400530942174\n",
      "Accuracy = 0.5, Loss = 0.6810683647882317\n",
      "Accuracy = 0.5, Loss = 0.6805996142171825\n",
      "Accuracy = 0.5, Loss = 0.680133782522119\n",
      "Accuracy = 0.5, Loss = 0.6796708509280848\n",
      "Accuracy = 0.5, Loss = 0.6792108007442841\n",
      "Accuracy = 0.5, Loss = 0.6787536133642393\n",
      "Accuracy = 0.5, Loss = 0.6782992702659384\n",
      "Accuracy = 0.5, Loss = 0.6778477530119719\n",
      "Accuracy = 0.5, Loss = 0.6773990432496642\n",
      "Accuracy = 0.5, Loss = 0.6769531227111925\n",
      "Accuracy = 0.5, Loss = 0.6765099732136981\n",
      "Accuracy = 0.5, Loss = 0.6760695766593898\n",
      "Accuracy = 0.5, Loss = 0.6756319150356356\n",
      "Accuracy = 0.5, Loss = 0.6751969704150506\n",
      "Accuracy = 0.5, Loss = 0.6747647249555705\n",
      "Accuracy = 0.5, Loss = 0.674335160900522\n",
      "Accuracy = 0.5, Loss = 0.6739082605786822\n",
      "Accuracy = 0.5, Loss = 0.6734840064043301\n",
      "Accuracy = 0.5, Loss = 0.6730623808772903\n",
      "Accuracy = 0.5, Loss = 0.6726433665829687\n",
      "Accuracy = 0.5, Loss = 0.6722269461923815\n",
      "Accuracy = 0.5, Loss = 0.6718131024621731\n",
      "Accuracy = 0.5, Loss = 0.6714018182346316\n",
      "Accuracy = 0.5, Loss = 0.6709930764376908\n",
      "Accuracy = 0.5, Loss = 0.6705868600849304\n",
      "Accuracy = 0.5, Loss = 0.6701831522755648\n",
      "Accuracy = 0.5, Loss = 0.6697819361944269\n",
      "Accuracy = 0.5, Loss = 0.6693831951119441\n",
      "Accuracy = 0.5, Loss = 0.668986912384106\n",
      "Accuracy = 0.5, Loss = 0.6685930714524289\n",
      "Accuracy = 0.5, Loss = 0.6682016558439089\n",
      "Accuracy = 0.5, Loss = 0.6678126491709729\n",
      "Accuracy = 0.5, Loss = 0.6674260351314184\n",
      "Accuracy = 0.5, Loss = 0.6670417975083506\n",
      "Accuracy = 0.5, Loss = 0.6666599201701102\n",
      "Accuracy = 0.5, Loss = 0.6662803870701991\n",
      "Accuracy = 0.5, Loss = 0.6659031822471941\n",
      "Accuracy = 0.5, Loss = 0.6655282898246594\n",
      "Accuracy = 0.5, Loss = 0.6651556940110502\n",
      "Accuracy = 0.5, Loss = 0.6647853790996153\n",
      "Accuracy = 0.5, Loss = 0.6644173294682834\n",
      "Accuracy = 0.5, Loss = 0.6640515295795563\n",
      "Accuracy = 0.5, Loss = 0.6636879639803892\n",
      "Accuracy = 0.5, Loss = 0.6633266173020654\n",
      "Accuracy = 0.5, Loss = 0.66296747426007\n",
      "Accuracy = 0.5, Loss = 0.6626105196539528\n",
      "Accuracy = 0.5, Loss = 0.662255738367191\n",
      "Accuracy = 0.5, Loss = 0.6619031153670426\n",
      "Accuracy = 0.5, Loss = 0.6615526357043986\n",
      "Accuracy = 0.5, Loss = 0.6612042845136271\n",
      "Accuracy = 0.5, Loss = 0.6608580470124147\n",
      "Accuracy = 0.5, Loss = 0.6605139085016007\n",
      "Accuracy = 0.5, Loss = 0.6601718543650108\n",
      "Accuracy = 0.5, Loss = 0.6598318700692819\n",
      "Accuracy = 0.5, Loss = 0.6594939411636844\n",
      "Accuracy = 0.5, Loss = 0.6591580532799398\n",
      "Accuracy = 0.5, Loss = 0.6588241921320356\n",
      "Accuracy = 0.5, Loss = 0.6584923435160315\n",
      "Accuracy = 0.5, Loss = 0.6581624933098682\n",
      "Accuracy = 0.5, Loss = 0.6578346274731652\n",
      "Accuracy = 0.5, Loss = 0.6575087320470194\n",
      "Accuracy = 0.5, Loss = 0.657184793153798\n",
      "Accuracy = 0.5, Loss = 0.6568627969969277\n",
      "Accuracy = 0.5, Loss = 0.6565427298606805\n",
      "Accuracy = 0.5, Loss = 0.6562245781099553\n",
      "Accuracy = 0.5, Loss = 0.6559083281900565\n",
      "Accuracy = 0.5, Loss = 0.6555939666264693\n",
      "Accuracy = 0.5, Loss = 0.6552814800246306\n",
      "Accuracy = 0.5, Loss = 0.6549708550696981\n",
      "Accuracy = 0.5, Loss = 0.6546620785263131\n",
      "Accuracy = 0.5, Loss = 0.6543551372383654\n",
      "Accuracy = 0.5, Loss = 0.6540500181287497\n",
      "Accuracy = 0.5, Loss = 0.653746708199121\n",
      "Accuracy = 0.5, Loss = 0.6534451945296496\n",
      "Accuracy = 0.5, Loss = 0.6531454642787685\n",
      "Accuracy = 0.5, Loss = 0.6528475046829211\n",
      "Accuracy = 0.5, Loss = 0.6525513030563062\n",
      "Accuracy = 0.5, Loss = 0.6522568467906187\n",
      "Accuracy = 0.5, Loss = 0.6519641233547884\n",
      "Accuracy = 0.5, Loss = 0.6516731202947179\n",
      "Accuracy = 0.5, Loss = 0.6513838252330144\n",
      "Accuracy = 0.5, Loss = 0.6510962258687232\n",
      "Accuracy = 0.5, Loss = 0.6508103099770554\n",
      "Accuracy = 0.5, Loss = 0.6505260654091164\n",
      "Accuracy = 0.5, Loss = 0.6502434800916294\n",
      "Accuracy = 0.5, Loss = 0.6499625420266582\n",
      "Accuracy = 0.5, Loss = 0.6496832392913287\n",
      "Accuracy = 0.5, Loss = 0.6494055600375463\n",
      "Accuracy = 0.5, Loss = 0.6491294924917136\n",
      "Accuracy = 0.5, Loss = 0.6488550249544436\n",
      "Accuracy = 0.5, Loss = 0.648582145800274\n",
      "Accuracy = 0.5, Loss = 0.6483108434773779\n",
      "Accuracy = 0.5, Loss = 0.6480411065072722\n",
      "Accuracy = 0.5, Loss = 0.6477729234845273\n",
      "Accuracy = 0.5, Loss = 0.6475062830764712\n",
      "Accuracy = 0.5, Loss = 0.6472411740228953\n",
      "Accuracy = 0.5, Loss = 0.6469775851357571\n",
      "Accuracy = 0.5, Loss = 0.6467155052988818\n",
      "Accuracy = 0.5, Loss = 0.6464549234676633\n",
      "Accuracy = 0.5, Loss = 0.6461958286687615\n",
      "Accuracy = 0.5, Loss = 0.6459382099998021\n",
      "Accuracy = 0.5, Loss = 0.6456820566290721\n",
      "Accuracy = 0.5, Loss = 0.6454273577952137\n",
      "Accuracy = 0.5, Loss = 0.6451741028069213\n",
      "Accuracy = 0.5, Loss = 0.644922281042632\n",
      "Accuracy = 0.5, Loss = 0.6446718819502198\n",
      "Accuracy = 0.5, Loss = 0.6444228950466855\n",
      "Accuracy = 0.5, Loss = 0.6441753099178459\n",
      "Accuracy = 0.5, Loss = 0.6439291162180263\n",
      "Accuracy = 0.5, Loss = 0.6436843036697449\n",
      "Accuracy = 0.5, Loss = 0.6434408620634051\n",
      "Accuracy = 0.5, Loss = 0.6431987812569772\n",
      "Accuracy = 0.5, Loss = 0.6429580511756892\n",
      "Accuracy = 0.5, Loss = 0.6427186618117101\n",
      "Accuracy = 0.5, Loss = 0.6424806032238353\n",
      "Accuracy = 0.5, Loss = 0.6422438655371708\n",
      "Accuracy = 0.5, Loss = 0.6420084389428179\n",
      "Accuracy = 0.5, Loss = 0.6417743136975557\n",
      "Accuracy = 0.5, Loss = 0.6415414801235244\n",
      "Accuracy = 0.5, Loss = 0.6413099286079074\n",
      "Accuracy = 0.5, Loss = 0.6410796496026149\n",
      "Accuracy = 0.5, Loss = 0.6408506336239641\n",
      "Accuracy = 0.5, Loss = 0.640622871252361\n",
      "Accuracy = 0.5, Loss = 0.6403963531319825\n",
      "Accuracy = 0.5, Loss = 0.6401710699704569\n",
      "Accuracy = 0.5, Loss = 0.6399470125385451\n",
      "Accuracy = 0.5, Loss = 0.6397241716698212\n",
      "Accuracy = 0.5, Loss = 0.6395025382603522\n",
      "Accuracy = 0.51, Loss = 0.63928210326838\n",
      "Accuracy = 0.51, Loss = 0.6390628577140012\n",
      "Accuracy = 0.51, Loss = 0.6388447926788472\n",
      "Accuracy = 0.51, Loss = 0.6386278993057661\n",
      "Accuracy = 0.51, Loss = 0.638412168798501\n",
      "Accuracy = 0.51, Loss = 0.6381975924213726\n",
      "Accuracy = 0.51, Loss = 0.637984161498959\n",
      "Accuracy = 0.51, Loss = 0.6377718674157764\n",
      "Accuracy = 0.51, Loss = 0.6375607016159607\n",
      "Accuracy = 0.51, Loss = 0.6373506556029491\n",
      "Accuracy = 0.51, Loss = 0.63714172093916\n",
      "Accuracy = 0.51, Loss = 0.6369338892456762\n",
      "Accuracy = 0.51, Loss = 0.6367271522019261\n",
      "Accuracy = 0.51, Loss = 0.6365215015453669\n",
      "Accuracy = 0.51, Loss = 0.6363169290711658\n",
      "Accuracy = 0.52, Loss = 0.6361134266318844\n",
      "Accuracy = 0.52, Loss = 0.6359109861371612\n",
      "Accuracy = 0.52, Loss = 0.6357095995533963\n",
      "Accuracy = 0.52, Loss = 0.635509258903434\n",
      "Accuracy = 0.52, Loss = 0.63530995626625\n",
      "Accuracy = 0.52, Loss = 0.635111683776634\n",
      "Accuracy = 0.52, Loss = 0.6349144336248769\n",
      "Accuracy = 0.52, Loss = 0.6347181980564567\n",
      "Accuracy = 0.52, Loss = 0.6345229693717253\n",
      "Accuracy = 0.52, Loss = 0.6343287399255955\n",
      "Accuracy = 0.52, Loss = 0.6341355021272296\n",
      "Accuracy = 0.52, Loss = 0.6339432484397265\n",
      "Accuracy = 0.52, Loss = 0.6337519713798134\n",
      "Accuracy = 0.52, Loss = 0.633561663517533\n",
      "Accuracy = 0.52, Loss = 0.6333723174759354\n",
      "Accuracy = 0.52, Loss = 0.6331839259307691\n",
      "Accuracy = 0.52, Loss = 0.6329964816101729\n",
      "Accuracy = 0.52, Loss = 0.6328099772943676\n",
      "Accuracy = 0.52, Loss = 0.6326244058153516\n",
      "Accuracy = 0.52, Loss = 0.6324397600565923\n",
      "Accuracy = 0.52, Loss = 0.6322560329527235\n",
      "Accuracy = 0.52, Loss = 0.6320732174892387\n",
      "Accuracy = 0.52, Loss = 0.6318913067021898\n",
      "Accuracy = 0.52, Loss = 0.6317102936778834\n",
      "Accuracy = 0.52, Loss = 0.6315301715525786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.52, Loss = 0.6313509335121867\n",
      "Accuracy = 0.52, Loss = 0.6311725727919714\n",
      "Accuracy = 0.52, Loss = 0.6309950826762485\n",
      "Accuracy = 0.52, Loss = 0.6308184564980883\n",
      "Accuracy = 0.52, Loss = 0.6306426876390188\n",
      "Accuracy = 0.52, Loss = 0.6304677695287279\n",
      "Accuracy = 0.52, Loss = 0.6302936956447686\n",
      "Accuracy = 0.52, Loss = 0.6301204595122648\n",
      "Accuracy = 0.52, Loss = 0.6299480547036169\n",
      "Accuracy = 0.52, Loss = 0.6297764748382095\n",
      "Accuracy = 0.52, Loss = 0.6296057135821205\n",
      "Accuracy = 0.52, Loss = 0.6294357646478281\n",
      "Accuracy = 0.52, Loss = 0.6292666217939248\n",
      "Accuracy = 0.52, Loss = 0.629098278824825\n",
      "Accuracy = 0.52, Loss = 0.6289307295904804\n",
      "Accuracy = 0.52, Loss = 0.6287639679860909\n",
      "Accuracy = 0.53, Loss = 0.628597987951822\n",
      "Accuracy = 0.53, Loss = 0.6284327834725175\n",
      "Accuracy = 0.53, Loss = 0.6282683485774174\n",
      "Accuracy = 0.53, Loss = 0.6281046773398753\n",
      "Accuracy = 0.53, Loss = 0.6279417638770788\n",
      "Accuracy = 0.53, Loss = 0.6277796023497659\n",
      "Accuracy = 0.53, Loss = 0.6276181869619496\n",
      "Accuracy = 0.53, Loss = 0.627457511960637\n",
      "Accuracy = 0.54, Loss = 0.6272975716355551\n",
      "Accuracy = 0.54, Loss = 0.6271383603188725\n",
      "Accuracy = 0.54, Loss = 0.6269798723849269\n",
      "Accuracy = 0.54, Loss = 0.6268221022499506\n",
      "Accuracy = 0.54, Loss = 0.6266650443717985\n",
      "Accuracy = 0.54, Loss = 0.6265086932496772\n",
      "Accuracy = 0.54, Loss = 0.6263530434238734\n",
      "Accuracy = 0.54, Loss = 0.6261980894754885\n",
      "Accuracy = 0.54, Loss = 0.6260438260261669\n",
      "Accuracy = 0.54, Loss = 0.6258902477378323\n",
      "Accuracy = 0.54, Loss = 0.625737349312421\n",
      "Accuracy = 0.55, Loss = 0.6255851254916179\n",
      "Accuracy = 0.55, Loss = 0.6254335710565944\n",
      "Accuracy = 0.55, Loss = 0.6252826808277451\n",
      "Accuracy = 0.55, Loss = 0.6251324496644286\n",
      "Accuracy = 0.55, Loss = 0.6249828724647077\n",
      "Accuracy = 0.55, Loss = 0.62483394416509\n",
      "Accuracy = 0.55, Loss = 0.6246856597402729\n",
      "Accuracy = 0.55, Loss = 0.624538014202886\n",
      "Accuracy = 0.55, Loss = 0.624391002603238\n",
      "Accuracy = 0.55, Loss = 0.6242446200290616\n",
      "Accuracy = 0.55, Loss = 0.6240988616052627\n",
      "Accuracy = 0.56, Loss = 0.6239537224936691\n",
      "Accuracy = 0.56, Loss = 0.6238091978927804\n",
      "Accuracy = 0.57, Loss = 0.62366528303752\n",
      "Accuracy = 0.57, Loss = 0.6235219731989871\n",
      "Accuracy = 0.57, Loss = 0.6233792636842108\n",
      "Accuracy = 0.58, Loss = 0.623237149835906\n",
      "Accuracy = 0.58, Loss = 0.6230956270322289\n",
      "Accuracy = 0.58, Loss = 0.6229546906865344\n",
      "Accuracy = 0.58, Loss = 0.6228143362471363\n",
      "Accuracy = 0.58, Loss = 0.6226745591970655\n",
      "Accuracy = 0.58, Loss = 0.6225353550538327\n",
      "Accuracy = 0.58, Loss = 0.6223967193691905\n",
      "Accuracy = 0.58, Loss = 0.6222586477288963\n",
      "Accuracy = 0.58, Loss = 0.6221211357524785\n",
      "Accuracy = 0.58, Loss = 0.6219841790930025\n",
      "Accuracy = 0.58, Loss = 0.6218477734368366\n",
      "Accuracy = 0.58, Loss = 0.6217119145034232\n",
      "Accuracy = 0.58, Loss = 0.621576598045047\n",
      "Accuracy = 0.58, Loss = 0.6214418198466053\n",
      "Accuracy = 0.58, Loss = 0.6213075757253835\n",
      "Accuracy = 0.58, Loss = 0.6211738615308253\n",
      "Accuracy = 0.58, Loss = 0.6210406731443093\n",
      "Accuracy = 0.58, Loss = 0.6209080064789244\n",
      "Accuracy = 0.58, Loss = 0.6207758574792477\n",
      "Accuracy = 0.58, Loss = 0.6206442221211224\n",
      "Accuracy = 0.58, Loss = 0.6205130964114379\n",
      "Accuracy = 0.58, Loss = 0.6203824763879102\n",
      "Accuracy = 0.58, Loss = 0.620252358118865\n",
      "Accuracy = 0.58, Loss = 0.6201227377030197\n",
      "Accuracy = 0.58, Loss = 0.6199936112692698\n",
      "Accuracy = 0.58, Loss = 0.6198649749764723\n",
      "Accuracy = 0.58, Loss = 0.6197368250132358\n",
      "Accuracy = 0.58, Loss = 0.6196091575977062\n",
      "Accuracy = 0.58, Loss = 0.6194819689773569\n",
      "Accuracy = 0.58, Loss = 0.61935525542878\n",
      "Accuracy = 0.58, Loss = 0.6192290132574781\n",
      "Accuracy = 0.59, Loss = 0.6191032387976567\n",
      "Accuracy = 0.59, Loss = 0.6189779284120187\n",
      "Accuracy = 0.59, Loss = 0.6188530784915605\n",
      "Accuracy = 0.59, Loss = 0.6187286854553677\n",
      "Accuracy = 0.59, Loss = 0.6186047457504145\n",
      "Accuracy = 0.59, Loss = 0.6184812558513608\n",
      "Accuracy = 0.59, Loss = 0.6183582122603538\n",
      "Accuracy = 0.59, Loss = 0.6182356115068296\n",
      "Accuracy = 0.6, Loss = 0.6181134501473146\n",
      "Accuracy = 0.6, Loss = 0.6179917247652305\n",
      "Accuracy = 0.6, Loss = 0.6178704319706986\n",
      "Accuracy = 0.6, Loss = 0.6177495684003462\n",
      "Accuracy = 0.61, Loss = 0.6176291307171146\n",
      "Accuracy = 0.61, Loss = 0.6175091156100659\n",
      "Accuracy = 0.61, Loss = 0.6173895197941947\n",
      "Accuracy = 0.62, Loss = 0.6172703400102371\n",
      "Accuracy = 0.62, Loss = 0.6171515730244841\n",
      "Accuracy = 0.62, Loss = 0.6170332156285941\n",
      "Accuracy = 0.62, Loss = 0.616915264639407\n",
      "Accuracy = 0.62, Loss = 0.6167977168987603\n",
      "Accuracy = 0.62, Loss = 0.6166805692733051\n",
      "Accuracy = 0.62, Loss = 0.6165638186543242\n",
      "Accuracy = 0.62, Loss = 0.6164474619575503\n",
      "Accuracy = 0.62, Loss = 0.6163314961229875\n",
      "Accuracy = 0.62, Loss = 0.6162159181147302\n",
      "Accuracy = 0.62, Loss = 0.6161007249207876\n",
      "Accuracy = 0.63, Loss = 0.6159859135529053\n",
      "Accuracy = 0.63, Loss = 0.6158714810463912\n",
      "Accuracy = 0.63, Loss = 0.6157574244599394\n",
      "Accuracy = 0.63, Loss = 0.615643740875459\n",
      "Accuracy = 0.63, Loss = 0.6155304273979009\n",
      "Accuracy = 0.64, Loss = 0.6154174811550855\n",
      "Accuracy = 0.64, Loss = 0.6153048992975348\n",
      "Accuracy = 0.64, Loss = 0.6151926789983025\n",
      "Accuracy = 0.64, Loss = 0.615080817452806\n",
      "Accuracy = 0.64, Loss = 0.61496931187866\n",
      "Accuracy = 0.64, Loss = 0.6148581595155111\n",
      "Accuracy = 0.64, Loss = 0.6147473576248723\n",
      "Accuracy = 0.64, Loss = 0.6146369034899607\n",
      "Accuracy = 0.64, Loss = 0.6145267944155345\n",
      "Accuracy = 0.64, Loss = 0.6144170277277307\n",
      "Accuracy = 0.64, Loss = 0.6143076007739067\n",
      "Accuracy = 0.64, Loss = 0.6141985109224796\n",
      "Accuracy = 0.64, Loss = 0.6140897555627687\n",
      "Accuracy = 0.64, Loss = 0.6139813321048377\n",
      "Accuracy = 0.64, Loss = 0.613873237979339\n",
      "Accuracy = 0.64, Loss = 0.6137654706373584\n",
      "Accuracy = 0.64, Loss = 0.6136580275502612\n",
      "Accuracy = 0.64, Loss = 0.613550906209539\n",
      "Accuracy = 0.64, Loss = 0.6134441041266583\n",
      "Accuracy = 0.64, Loss = 0.6133376188329078\n",
      "Accuracy = 0.64, Loss = 0.6132314478792511\n",
      "Accuracy = 0.64, Loss = 0.6131255888361747\n",
      "Accuracy = 0.64, Loss = 0.6130200392935425\n",
      "Accuracy = 0.64, Loss = 0.6129147968604475\n",
      "Accuracy = 0.64, Loss = 0.6128098591650657\n",
      "Accuracy = 0.64, Loss = 0.6127052238545115\n",
      "Accuracy = 0.64, Loss = 0.6126008885946945\n",
      "Accuracy = 0.64, Loss = 0.6124968510701746\n",
      "Accuracy = 0.64, Loss = 0.6123931089840218\n",
      "Accuracy = 0.66, Loss = 0.6122896600576732\n",
      "Accuracy = 0.66, Loss = 0.6121865020307945\n",
      "Accuracy = 0.66, Loss = 0.6120836326611402\n",
      "Accuracy = 0.66, Loss = 0.6119810497244156\n",
      "Accuracy = 0.67, Loss = 0.6118787510141385\n",
      "Accuracy = 0.67, Loss = 0.611776734341504\n",
      "Accuracy = 0.68, Loss = 0.6116749975352492\n",
      "Accuracy = 0.68, Loss = 0.6115735384415175\n",
      "Accuracy = 0.68, Loss = 0.6114723549237266\n",
      "Accuracy = 0.69, Loss = 0.6113714448624346\n",
      "Accuracy = 0.69, Loss = 0.6112708061552088\n",
      "Accuracy = 0.71, Loss = 0.6111704367164953\n",
      "Accuracy = 0.71, Loss = 0.6110703344774889\n",
      "Accuracy = 0.71, Loss = 0.610970497386004\n",
      "Accuracy = 0.71, Loss = 0.6108709234063462\n",
      "Accuracy = 0.71, Loss = 0.6107716105191858\n",
      "Accuracy = 0.71, Loss = 0.6106725567214315\n",
      "Accuracy = 0.71, Loss = 0.6105737600261049\n",
      "Accuracy = 0.71, Loss = 0.6104752184622153\n",
      "Accuracy = 0.71, Loss = 0.6103769300746373\n",
      "Accuracy = 0.71, Loss = 0.6102788929239871\n",
      "Accuracy = 0.71, Loss = 0.6101811050865013\n",
      "Accuracy = 0.71, Loss = 0.6100835646539151\n",
      "Accuracy = 0.71, Loss = 0.6099862697333428\n",
      "Accuracy = 0.71, Loss = 0.6098892184471585\n",
      "Accuracy = 0.71, Loss = 0.6097924089328772\n",
      "Accuracy = 0.71, Loss = 0.609695839343038\n",
      "Accuracy = 0.71, Loss = 0.6095995078450851\n",
      "Accuracy = 0.71, Loss = 0.609503412621255\n",
      "Accuracy = 0.71, Loss = 0.6094075518684599\n",
      "Accuracy = 0.71, Loss = 0.6093119237981725\n",
      "Accuracy = 0.71, Loss = 0.6092165266363135\n",
      "Accuracy = 0.71, Loss = 0.6091213586231398\n",
      "Accuracy = 0.71, Loss = 0.6090264180131306\n",
      "Accuracy = 0.71, Loss = 0.6089317030748778\n",
      "Accuracy = 0.71, Loss = 0.6088372120909757\n",
      "Accuracy = 0.71, Loss = 0.6087429433579112\n",
      "Accuracy = 0.71, Loss = 0.6086488951859552\n",
      "Accuracy = 0.71, Loss = 0.6085550658990541\n",
      "Accuracy = 0.71, Loss = 0.6084614538347243\n",
      "Accuracy = 0.71, Loss = 0.6083680573439442\n",
      "Accuracy = 0.71, Loss = 0.6082748747910497\n",
      "Accuracy = 0.71, Loss = 0.6081819045536297\n",
      "Accuracy = 0.71, Loss = 0.6080891450224203\n",
      "Accuracy = 0.71, Loss = 0.6079965946012038\n",
      "Accuracy = 0.71, Loss = 0.6079042517067044\n",
      "Accuracy = 0.71, Loss = 0.6078121147684883\n",
      "Accuracy = 0.72, Loss = 0.6077201822288603\n",
      "Accuracy = 0.72, Loss = 0.6076284525427657\n",
      "Accuracy = 0.72, Loss = 0.60753692417769\n",
      "Accuracy = 0.72, Loss = 0.6074455956135595\n",
      "Accuracy = 0.72, Loss = 0.6073544653426437\n",
      "Accuracy = 0.72, Loss = 0.6072635318694592\n",
      "Accuracy = 0.72, Loss = 0.6071727937106703\n",
      "Accuracy = 0.72, Loss = 0.6070822493949959\n",
      "Accuracy = 0.72, Loss = 0.6069918974631121\n",
      "Accuracy = 0.72, Loss = 0.6069017364675592\n",
      "Accuracy = 0.72, Loss = 0.6068117649726473\n",
      "Accuracy = 0.72, Loss = 0.6067219815543633\n",
      "Accuracy = 0.72, Loss = 0.6066323848002781\n",
      "Accuracy = 0.72, Loss = 0.6065429733094554\n",
      "Accuracy = 0.72, Loss = 0.6064537456923604\n",
      "Accuracy = 0.72, Loss = 0.6063647005707691\n",
      "Accuracy = 0.72, Loss = 0.6062758365776795\n",
      "Accuracy = 0.72, Loss = 0.6061871523572215\n",
      "Accuracy = 0.72, Loss = 0.6060986465645696\n",
      "Accuracy = 0.72, Loss = 0.6060103178658538\n",
      "Accuracy = 0.72, Loss = 0.6059221649380739\n",
      "Accuracy = 0.72, Loss = 0.605834186469013\n",
      "Accuracy = 0.72, Loss = 0.6057463811571503\n",
      "Accuracy = 0.72, Loss = 0.6056587477115776\n",
      "Accuracy = 0.73, Loss = 0.6055712848519142\n",
      "Accuracy = 0.73, Loss = 0.605483991308223\n",
      "Accuracy = 0.73, Loss = 0.6053968658209271\n",
      "Accuracy = 0.73, Loss = 0.6053099071407282\n",
      "Accuracy = 0.73, Loss = 0.6052231140285231\n",
      "Accuracy = 0.73, Loss = 0.6051364852553236\n",
      "Accuracy = 0.74, Loss = 0.6050500196021759\n",
      "Accuracy = 0.75, Loss = 0.6049637158600785\n",
      "Accuracy = 0.75, Loss = 0.6048775728299056\n",
      "Accuracy = 0.75, Loss = 0.604791589322326\n",
      "Accuracy = 0.75, Loss = 0.6047057641577258\n",
      "Accuracy = 0.75, Loss = 0.6046200961661301\n",
      "Accuracy = 0.76, Loss = 0.6045345841871262\n",
      "Accuracy = 0.76, Loss = 0.6044492270697871\n",
      "Accuracy = 0.77, Loss = 0.6043640236725956\n",
      "Accuracy = 0.77, Loss = 0.6042789728633686\n",
      "Accuracy = 0.78, Loss = 0.6041940735191828\n",
      "Accuracy = 0.78, Loss = 0.6041093245262996\n",
      "Accuracy = 0.78, Loss = 0.6040247247800918\n",
      "Accuracy = 0.79, Loss = 0.6039402731849717\n",
      "Accuracy = 0.79, Loss = 0.6038559686543166\n",
      "Accuracy = 0.79, Loss = 0.6037718101103977\n",
      "Accuracy = 0.79, Loss = 0.6036877964843089\n",
      "Accuracy = 0.8, Loss = 0.6036039267158959\n",
      "Accuracy = 0.8, Loss = 0.6035201997536851\n",
      "Accuracy = 0.8, Loss = 0.6034366145548143\n",
      "Accuracy = 0.8, Loss = 0.6033531700849638\n",
      "Accuracy = 0.8, Loss = 0.6032698653182869\n",
      "Accuracy = 0.8, Loss = 0.6031866992373421\n",
      "Accuracy = 0.8, Loss = 0.6031036708330251\n",
      "Accuracy = 0.8, Loss = 0.6030207791045024\n",
      "Accuracy = 0.8, Loss = 0.6029380230591433\n",
      "Accuracy = 0.8, Loss = 0.6028554017124559\n",
      "Accuracy = 0.8, Loss = 0.6027729140880183\n",
      "Accuracy = 0.8, Loss = 0.6026905592174165\n",
      "Accuracy = 0.8, Loss = 0.6026083361401785\n",
      "Accuracy = 0.8, Loss = 0.6025262439037096\n",
      "Accuracy = 0.8, Loss = 0.60244428156323\n",
      "Accuracy = 0.8, Loss = 0.6023624481817113\n",
      "Accuracy = 0.8, Loss = 0.6022807428298125\n",
      "Accuracy = 0.8, Loss = 0.6021991645858199\n",
      "Accuracy = 0.8, Loss = 0.6021177125355845\n",
      "Accuracy = 0.8, Loss = 0.6020363857724604\n",
      "Accuracy = 0.8, Loss = 0.6019551833972446\n",
      "Accuracy = 0.8, Loss = 0.6018741045181168\n",
      "Accuracy = 0.8, Loss = 0.601793148250579\n",
      "Accuracy = 0.8, Loss = 0.6017123137173968\n",
      "Accuracy = 0.8, Loss = 0.6016316000485408\n",
      "Accuracy = 0.8, Loss = 0.6015510063811269\n",
      "Accuracy = 0.8, Loss = 0.6014705318593602\n",
      "Accuracy = 0.8, Loss = 0.6013901756344755\n",
      "Accuracy = 0.8, Loss = 0.6013099368646819\n",
      "Accuracy = 0.8, Loss = 0.6012298147151057\n",
      "Accuracy = 0.8, Loss = 0.6011498083577339\n",
      "Accuracy = 0.8, Loss = 0.6010699169713584\n",
      "Accuracy = 0.8, Loss = 0.6009901397415213\n",
      "Accuracy = 0.8, Loss = 0.6009104758604602\n",
      "Accuracy = 0.8, Loss = 0.6008309245270524\n",
      "Accuracy = 0.8, Loss = 0.600751484946763\n",
      "Accuracy = 0.8, Loss = 0.6006721563315895\n",
      "Accuracy = 0.8, Loss = 0.6005929379000096\n",
      "Accuracy = 0.8, Loss = 0.6005138288769285\n",
      "Accuracy = 0.8, Loss = 0.6004348284936254\n",
      "Accuracy = 0.8, Loss = 0.6003559359877034\n",
      "Accuracy = 0.8, Loss = 0.6002771506030371\n",
      "Accuracy = 0.8, Loss = 0.6001984715897213\n",
      "Accuracy = 0.8, Loss = 0.6001198982040201\n",
      "Accuracy = 0.8, Loss = 0.6000414297083182\n",
      "Accuracy = 0.8, Loss = 0.599963065371069\n",
      "Accuracy = 0.8, Loss = 0.5998848044667462\n",
      "Accuracy = 0.8, Loss = 0.5998066462757943\n",
      "Accuracy = 0.8, Loss = 0.5997285900845803\n",
      "Accuracy = 0.8, Loss = 0.5996506351853452\n",
      "Accuracy = 0.8, Loss = 0.5995727808761557\n",
      "Accuracy = 0.8, Loss = 0.5994950264608575\n",
      "Accuracy = 0.8, Loss = 0.5994173712490264\n",
      "Accuracy = 0.8, Loss = 0.5993398145559236\n",
      "Accuracy = 0.8, Loss = 0.5992623557024472\n",
      "Accuracy = 0.8, Loss = 0.5991849940150887\n",
      "Accuracy = 0.8, Loss = 0.5991077288258844\n",
      "Accuracy = 0.8, Loss = 0.5990305594723715\n",
      "Accuracy = 0.8, Loss = 0.5989534852975432\n",
      "Accuracy = 0.8, Loss = 0.5988765056498043\n",
      "Accuracy = 0.8, Loss = 0.5987996198829257\n",
      "Accuracy = 0.8, Loss = 0.5987228273560016\n",
      "Accuracy = 0.8, Loss = 0.5986461274334057\n",
      "Accuracy = 0.8, Loss = 0.5985695194847469\n",
      "Accuracy = 0.8, Loss = 0.5984930028848288\n",
      "Accuracy = 0.8, Loss = 0.5984165770136041\n",
      "Accuracy = 0.81, Loss = 0.5983402412561349\n",
      "Accuracy = 0.81, Loss = 0.5982639950025498\n",
      "Accuracy = 0.81, Loss = 0.5981878376480019\n",
      "Accuracy = 0.81, Loss = 0.5981117685926287\n",
      "Accuracy = 0.81, Loss = 0.5980357872415106\n",
      "Accuracy = 0.81, Loss = 0.5979598930046299\n",
      "Accuracy = 0.81, Loss = 0.5978840852968312\n",
      "Accuracy = 0.81, Loss = 0.5978083635377818\n",
      "Accuracy = 0.81, Loss = 0.597732727151931\n",
      "Accuracy = 0.81, Loss = 0.5976571755684721\n",
      "Accuracy = 0.81, Loss = 0.5975817082213024\n",
      "Accuracy = 0.81, Loss = 0.597506324548985\n",
      "Accuracy = 0.82, Loss = 0.5974310239947106\n",
      "Accuracy = 0.83, Loss = 0.5973558060062594\n",
      "Accuracy = 0.85, Loss = 0.5972806700359627\n",
      "Accuracy = 0.86, Loss = 0.5972056155406669\n",
      "Accuracy = 0.86, Loss = 0.5971306419816945\n",
      "Accuracy = 0.87, Loss = 0.5970557488248096\n",
      "Accuracy = 0.87, Loss = 0.5969809355401786\n",
      "Accuracy = 0.87, Loss = 0.5969062016023367\n",
      "Accuracy = 0.87, Loss = 0.5968315464901497\n",
      "Accuracy = 0.87, Loss = 0.5967569696867802\n",
      "Accuracy = 0.87, Loss = 0.5966824706796507\n",
      "Accuracy = 0.87, Loss = 0.5966080489604096\n",
      "Accuracy = 0.87, Loss = 0.5965337040248957\n",
      "Accuracy = 0.87, Loss = 0.5964594353731042\n",
      "Accuracy = 0.87, Loss = 0.5963852425091517\n",
      "Accuracy = 0.87, Loss = 0.5963111249412435\n",
      "Accuracy = 0.87, Loss = 0.5962370821816381\n",
      "Accuracy = 0.87, Loss = 0.5961631137466162\n",
      "Accuracy = 0.87, Loss = 0.5960892191564447\n",
      "Accuracy = 0.87, Loss = 0.5960153979353465\n",
      "Accuracy = 0.87, Loss = 0.5959416496114658\n",
      "Accuracy = 0.87, Loss = 0.5958679737168366\n",
      "Accuracy = 0.87, Loss = 0.5957943697873513\n",
      "Accuracy = 0.87, Loss = 0.5957208373627277\n",
      "Accuracy = 0.87, Loss = 0.5956473759864778\n",
      "Accuracy = 0.87, Loss = 0.5955739852058769\n",
      "Accuracy = 0.87, Loss = 0.5955006645719313\n",
      "Accuracy = 0.87, Loss = 0.5954274136393494\n",
      "Accuracy = 0.87, Loss = 0.5953542319665095\n",
      "Accuracy = 0.87, Loss = 0.5952811191154301\n",
      "Accuracy = 0.87, Loss = 0.5952080746517402\n",
      "Accuracy = 0.87, Loss = 0.5951350981446485\n",
      "Accuracy = 0.87, Loss = 0.5950621891669147\n",
      "Accuracy = 0.87, Loss = 0.5949893472948196\n",
      "Accuracy = 0.87, Loss = 0.5949165721081361\n",
      "Accuracy = 0.87, Loss = 0.5948438631901007\n",
      "Accuracy = 0.87, Loss = 0.5947712201273844\n",
      "Accuracy = 0.87, Loss = 0.5946986425100642\n",
      "Accuracy = 0.87, Loss = 0.5946261299315957\n",
      "Accuracy = 0.87, Loss = 0.5945536819887842\n",
      "Accuracy = 0.87, Loss = 0.5944812982817572\n",
      "Accuracy = 0.87, Loss = 0.5944089784139377\n",
      "Accuracy = 0.87, Loss = 0.5943367219920157\n",
      "Accuracy = 0.87, Loss = 0.5942645286259223\n",
      "Accuracy = 0.87, Loss = 0.5941923979288015\n",
      "Accuracy = 0.87, Loss = 0.5941203295169853\n",
      "Accuracy = 0.87, Loss = 0.594048323009966\n",
      "Accuracy = 0.87, Loss = 0.5939763780303703\n",
      "Accuracy = 0.87, Loss = 0.5939044942039333\n",
      "Accuracy = 0.87, Loss = 0.5938326711594732\n",
      "Accuracy = 0.87, Loss = 0.5937609085288654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.87, Loss = 0.593689205947017\n",
      "Accuracy = 0.87, Loss = 0.5936175630518418\n",
      "Accuracy = 0.87, Loss = 0.5935459794842357\n",
      "Accuracy = 0.87, Loss = 0.5934744548880514\n",
      "Accuracy = 0.87, Loss = 0.5934029889100741\n",
      "Accuracy = 0.87, Loss = 0.5933315811999974\n",
      "Accuracy = 0.87, Loss = 0.5932602314103993\n",
      "Accuracy = 0.87, Loss = 0.5931889391967171\n",
      "Accuracy = 0.87, Loss = 0.5931177042172255\n",
      "Accuracy = 0.87, Loss = 0.5930465261330111\n",
      "Accuracy = 0.87, Loss = 0.5929754046079513\n",
      "Accuracy = 0.87, Loss = 0.5929043393086885\n",
      "Accuracy = 0.87, Loss = 0.5928333299046091\n",
      "Accuracy = 0.87, Loss = 0.5927623760678207\n",
      "Accuracy = 0.87, Loss = 0.5926914774731277\n",
      "Accuracy = 0.87, Loss = 0.5926206337980114\n",
      "Accuracy = 0.87, Loss = 0.5925498447226059\n",
      "Accuracy = 0.87, Loss = 0.5924791099296765\n",
      "Accuracy = 0.87, Loss = 0.5924084291045978\n",
      "Accuracy = 0.87, Loss = 0.5923378019353331\n",
      "Accuracy = 0.87, Loss = 0.5922672281124111\n",
      "Accuracy = 0.87, Loss = 0.5921967073289057\n",
      "Accuracy = 0.87, Loss = 0.5921262392804153\n",
      "Accuracy = 0.87, Loss = 0.5920558236650397\n",
      "Accuracy = 0.87, Loss = 0.5919854601833621\n",
      "Accuracy = 0.87, Loss = 0.5919151485384259\n",
      "Accuracy = 0.87, Loss = 0.5918448884357161\n",
      "Accuracy = 0.87, Loss = 0.5917746795831388\n",
      "Accuracy = 0.87, Loss = 0.5917045216909991\n",
      "Accuracy = 0.87, Loss = 0.5916344144719837\n",
      "Accuracy = 0.87, Loss = 0.5915643576411395\n",
      "Accuracy = 0.87, Loss = 0.5914943509158546\n",
      "Accuracy = 0.87, Loss = 0.5914243940158389\n",
      "Accuracy = 0.87, Loss = 0.591354486663104\n",
      "Accuracy = 0.87, Loss = 0.5912846285819447\n",
      "Accuracy = 0.87, Loss = 0.59121481949892\n",
      "Accuracy = 0.87, Loss = 0.5911450591428342\n",
      "Accuracy = 0.87, Loss = 0.591075347244718\n",
      "Accuracy = 0.87, Loss = 0.5910056835378092\n",
      "Accuracy = 0.87, Loss = 0.5909360677575368\n",
      "Accuracy = 0.87, Loss = 0.5908664996415002\n",
      "Accuracy = 0.87, Loss = 0.5907969789294517\n",
      "Accuracy = 0.87, Loss = 0.5907275053632796\n",
      "Accuracy = 0.87, Loss = 0.5906580786869893\n",
      "Accuracy = 0.87, Loss = 0.5905886986466862\n",
      "Accuracy = 0.87, Loss = 0.5905193649905582\n",
      "Accuracy = 0.87, Loss = 0.5904500774688581\n",
      "Accuracy = 0.87, Loss = 0.5903808358338861\n",
      "Accuracy = 0.87, Loss = 0.5903116398399736\n",
      "Accuracy = 0.87, Loss = 0.5902424892434659\n",
      "Accuracy = 0.87, Loss = 0.5901733838027047\n",
      "Accuracy = 0.87, Loss = 0.5901043232780128\n",
      "Accuracy = 0.87, Loss = 0.5900353074316762\n",
      "Accuracy = 0.87, Loss = 0.5899663360279287\n",
      "Accuracy = 0.87, Loss = 0.5898974088329354\n",
      "Accuracy = 0.87, Loss = 0.5898285256147758\n",
      "Accuracy = 0.87, Loss = 0.5897596861434297\n",
      "Accuracy = 0.88, Loss = 0.589690890190759\n",
      "Accuracy = 0.88, Loss = 0.5896221375304941\n",
      "Accuracy = 0.88, Loss = 0.5895534279382164\n",
      "Accuracy = 0.88, Loss = 0.589484761191345\n",
      "Accuracy = 0.88, Loss = 0.5894161370691196\n",
      "Accuracy = 0.88, Loss = 0.5893475553525852\n",
      "Accuracy = 0.88, Loss = 0.5892790158245794\n",
      "Accuracy = 0.88, Loss = 0.589210518269714\n",
      "Accuracy = 0.88, Loss = 0.5891420624743633\n",
      "Accuracy = 0.88, Loss = 0.5890736482266472\n",
      "Accuracy = 0.88, Loss = 0.5890052753164178\n",
      "Accuracy = 0.89, Loss = 0.5889369435352445\n",
      "Accuracy = 0.89, Loss = 0.5888686526764\n",
      "Accuracy = 0.89, Loss = 0.5888004025348451\n",
      "Accuracy = 0.89, Loss = 0.5887321929072167\n",
      "Accuracy = 0.89, Loss = 0.5886640235918108\n",
      "Accuracy = 0.89, Loss = 0.5885958943885714\n",
      "Accuracy = 0.89, Loss = 0.5885278050990752\n",
      "Accuracy = 0.9, Loss = 0.5884597555265184\n",
      "Accuracy = 0.9, Loss = 0.588391745475703\n",
      "Accuracy = 0.9, Loss = 0.5883237747530238\n",
      "Accuracy = 0.9, Loss = 0.5882558431664543\n",
      "Accuracy = 0.9, Loss = 0.5881879505255347\n",
      "Accuracy = 0.9, Loss = 0.5881200966413578\n",
      "Accuracy = 0.9, Loss = 0.5880522813265556\n",
      "Accuracy = 0.9, Loss = 0.5879845043952886\n",
      "Accuracy = 0.91, Loss = 0.58791676566323\n",
      "Accuracy = 0.91, Loss = 0.5878490649475561\n",
      "Accuracy = 0.91, Loss = 0.587781402066931\n",
      "Accuracy = 0.92, Loss = 0.5877137768414965\n",
      "Accuracy = 0.92, Loss = 0.587646189092858\n",
      "Accuracy = 0.93, Loss = 0.5875786386440731\n",
      "Accuracy = 0.93, Loss = 0.5875111253196392\n",
      "Accuracy = 0.93, Loss = 0.5874436489454817\n",
      "Accuracy = 0.93, Loss = 0.5873762093489421\n",
      "Accuracy = 0.93, Loss = 0.5873088063587653\n",
      "Accuracy = 0.93, Loss = 0.5872414398050889\n",
      "Accuracy = 0.93, Loss = 0.5871741095194315\n",
      "Accuracy = 0.94, Loss = 0.58710681533468\n",
      "Accuracy = 0.94, Loss = 0.5870395570850798\n",
      "Accuracy = 0.94, Loss = 0.5869723346062224\n",
      "Accuracy = 0.94, Loss = 0.5869051477350338\n",
      "Accuracy = 0.94, Loss = 0.586837996309764\n",
      "Accuracy = 0.94, Loss = 0.5867708801699761\n",
      "Accuracy = 0.94, Loss = 0.586703799156535\n",
      "Accuracy = 0.94, Loss = 0.5866367531115967\n",
      "Accuracy = 0.94, Loss = 0.5865697418785963\n",
      "Accuracy = 0.94, Loss = 0.5865027653022391\n",
      "Accuracy = 0.94, Loss = 0.5864358232284896\n",
      "Accuracy = 0.94, Loss = 0.5863689155045592\n",
      "Accuracy = 0.94, Loss = 0.5863020419788978\n",
      "Accuracy = 0.94, Loss = 0.5862352025011829\n",
      "Accuracy = 0.94, Loss = 0.5861683969223087\n",
      "Accuracy = 0.94, Loss = 0.5861016250943767\n",
      "Accuracy = 0.94, Loss = 0.5860348868706847\n",
      "Accuracy = 0.94, Loss = 0.5859681821057181\n",
      "Accuracy = 0.94, Loss = 0.5859015106551382\n",
      "Accuracy = 0.94, Loss = 0.5858348723757739\n",
      "Accuracy = 0.94, Loss = 0.5857682671256114\n",
      "Accuracy = 0.94, Loss = 0.585701694763784\n",
      "Accuracy = 0.94, Loss = 0.5856351551505633\n",
      "Accuracy = 0.94, Loss = 0.5855686481473494\n",
      "Accuracy = 0.94, Loss = 0.5855021736166607\n",
      "Accuracy = 0.94, Loss = 0.5854357314221261\n",
      "Accuracy = 0.94, Loss = 0.5853693214284736\n",
      "Accuracy = 0.94, Loss = 0.5853029435015236\n",
      "Accuracy = 0.94, Loss = 0.5852365975081771\n",
      "Accuracy = 0.94, Loss = 0.5851702833164093\n",
      "Accuracy = 0.94, Loss = 0.5851040007952579\n",
      "Accuracy = 0.94, Loss = 0.5850377498148165\n",
      "Accuracy = 0.94, Loss = 0.5849715302462242\n",
      "Accuracy = 0.94, Loss = 0.5849053419616583\n",
      "Accuracy = 0.94, Loss = 0.5848391848343237\n",
      "Accuracy = 0.94, Loss = 0.5847730587384459\n",
      "Accuracy = 0.94, Loss = 0.584706963549262\n",
      "Accuracy = 0.94, Loss = 0.5846408991430116\n",
      "Accuracy = 0.94, Loss = 0.5845748653969293\n",
      "Accuracy = 0.94, Loss = 0.5845088621892357\n",
      "Accuracy = 0.94, Loss = 0.5844428893991297\n",
      "Accuracy = 0.94, Loss = 0.5843769469067797\n",
      "Accuracy = 0.94, Loss = 0.5843110345933159\n",
      "Accuracy = 0.94, Loss = 0.5842451523408221\n",
      "Accuracy = 0.94, Loss = 0.5841793000323273\n",
      "Accuracy = 0.94, Loss = 0.5841134775517991\n",
      "Accuracy = 0.94, Loss = 0.584047684784134\n",
      "Accuracy = 0.94, Loss = 0.5839819216151512\n",
      "Accuracy = 0.94, Loss = 0.5839161879315834\n",
      "Accuracy = 0.94, Loss = 0.583850483621071\n",
      "Accuracy = 0.94, Loss = 0.5837848085721521\n",
      "Accuracy = 0.94, Loss = 0.5837191626742575\n",
      "Accuracy = 0.94, Loss = 0.5836535458177015\n",
      "Accuracy = 0.94, Loss = 0.5835879578936747\n",
      "Accuracy = 0.94, Loss = 0.5835223987942376\n",
      "Accuracy = 0.94, Loss = 0.583456868412312\n",
      "Accuracy = 0.94, Loss = 0.583391366641675\n",
      "Accuracy = 0.94, Loss = 0.5833258933769511\n",
      "Accuracy = 0.94, Loss = 0.5832604485136048\n",
      "Accuracy = 0.94, Loss = 0.5831950319479342\n",
      "Accuracy = 0.94, Loss = 0.5831296435770643\n",
      "Accuracy = 0.94, Loss = 0.5830642832989394\n",
      "Accuracy = 0.94, Loss = 0.5829989510123158\n",
      "Accuracy = 0.94, Loss = 0.5829336466167562\n",
      "Accuracy = 0.94, Loss = 0.5828683700126222\n",
      "Accuracy = 0.94, Loss = 0.5828031211010678\n",
      "Accuracy = 0.94, Loss = 0.5827378997840322\n",
      "Accuracy = 0.94, Loss = 0.5826727059642347\n",
      "Accuracy = 0.94, Loss = 0.5826075395451658\n",
      "Accuracy = 0.94, Loss = 0.5825424004310834\n",
      "Accuracy = 0.94, Loss = 0.5824772885270041\n",
      "Accuracy = 0.94, Loss = 0.5824122037386982\n",
      "Accuracy = 0.94, Loss = 0.5823471459726831\n",
      "Accuracy = 0.94, Loss = 0.5822821151362166\n",
      "Accuracy = 0.94, Loss = 0.5822171111372909\n",
      "Accuracy = 0.94, Loss = 0.5821521338846268\n",
      "Accuracy = 0.94, Loss = 0.5820871832876675\n",
      "Accuracy = 0.94, Loss = 0.5820222592565714\n",
      "Accuracy = 0.94, Loss = 0.5819573617022082\n",
      "Accuracy = 0.94, Loss = 0.581892490536151\n",
      "Accuracy = 0.94, Loss = 0.5818276456706716\n",
      "Accuracy = 0.94, Loss = 0.581762827018734\n",
      "Accuracy = 0.94, Loss = 0.5816980344939886\n",
      "Accuracy = 0.94, Loss = 0.5816332680107673\n",
      "Accuracy = 0.94, Loss = 0.5815685274840764\n",
      "Accuracy = 0.94, Loss = 0.5815038128295925\n",
      "Accuracy = 0.94, Loss = 0.5814391239636552\n",
      "Accuracy = 0.94, Loss = 0.5813744608032626\n",
      "Accuracy = 0.94, Loss = 0.5813098232660657\n",
      "Accuracy = 0.94, Loss = 0.5812452112703631\n",
      "Accuracy = 0.94, Loss = 0.5811806247350947\n",
      "Accuracy = 0.94, Loss = 0.581116063579837\n",
      "Accuracy = 0.94, Loss = 0.581051527724798\n",
      "Accuracy = 0.94, Loss = 0.5809870170908107\n",
      "Accuracy = 0.94, Loss = 0.5809225315993297\n",
      "Accuracy = 0.94, Loss = 0.5808580711724245\n",
      "Accuracy = 0.94, Loss = 0.5807936357327744\n",
      "Accuracy = 0.94, Loss = 0.5807292252036644\n",
      "Accuracy = 0.94, Loss = 0.5806648395089793\n",
      "Accuracy = 0.94, Loss = 0.5806004785731986\n",
      "Accuracy = 0.94, Loss = 0.5805361423213924\n",
      "Accuracy = 0.94, Loss = 0.5804718306792153\n",
      "Accuracy = 0.94, Loss = 0.5804075435729019\n",
      "Accuracy = 0.94, Loss = 0.5803432809292627\n",
      "Accuracy = 0.94, Loss = 0.5802790426756781\n",
      "Accuracy = 0.94, Loss = 0.5802148287400943\n",
      "Accuracy = 0.94, Loss = 0.5801506390510184\n",
      "Accuracy = 0.94, Loss = 0.5800864735375137\n",
      "Accuracy = 0.95, Loss = 0.5800223321291952\n",
      "Accuracy = 0.95, Loss = 0.5799582147562241\n",
      "Accuracy = 0.95, Loss = 0.5798941213493047\n",
      "Accuracy = 0.95, Loss = 0.5798300518396786\n",
      "Accuracy = 0.95, Loss = 0.579766006159121\n",
      "Accuracy = 0.95, Loss = 0.5797019842399357\n",
      "Accuracy = 0.95, Loss = 0.5796379860149505\n",
      "Accuracy = 0.95, Loss = 0.5795740114175137\n",
      "Accuracy = 0.95, Loss = 0.5795100603814884\n",
      "Accuracy = 0.95, Loss = 0.5794461328412502\n",
      "Accuracy = 0.95, Loss = 0.5793822287316803\n",
      "Accuracy = 0.95, Loss = 0.5793183479881632\n",
      "Accuracy = 0.95, Loss = 0.5792544905465821\n",
      "Accuracy = 0.95, Loss = 0.5791906563433141\n",
      "Accuracy = 0.95, Loss = 0.5791268453152266\n",
      "Accuracy = 0.95, Loss = 0.5790630573996732\n",
      "Accuracy = 0.95, Loss = 0.5789992925344892\n",
      "Accuracy = 0.95, Loss = 0.5789355506579881\n",
      "Accuracy = 0.95, Loss = 0.5788718317089568\n",
      "Accuracy = 0.95, Loss = 0.5788081356266529\n",
      "Accuracy = 0.95, Loss = 0.5787444623507992\n",
      "Accuracy = 0.95, Loss = 0.5786808118215813\n",
      "Accuracy = 0.95, Loss = 0.5786171839796426\n",
      "Accuracy = 0.95, Loss = 0.5785535787660805\n",
      "Accuracy = 0.95, Loss = 0.5784899961224439\n",
      "Accuracy = 0.95, Loss = 0.5784264359907275\n",
      "Accuracy = 0.95, Loss = 0.5783628983133698\n",
      "Accuracy = 0.95, Loss = 0.5782993830332479\n",
      "Accuracy = 0.95, Loss = 0.5782358900936755\n",
      "Accuracy = 0.95, Loss = 0.5781724194383971\n",
      "Accuracy = 0.95, Loss = 0.5781089710115865\n",
      "Accuracy = 0.95, Loss = 0.5780455447578416\n",
      "Accuracy = 0.95, Loss = 0.5779821406221819\n",
      "Accuracy = 0.95, Loss = 0.5779187585500444\n",
      "Accuracy = 0.98, Loss = 0.57785539848728\n",
      "Accuracy = 0.98, Loss = 0.5777920603801507\n",
      "Accuracy = 0.98, Loss = 0.5777287441753256\n",
      "Accuracy = 0.98, Loss = 0.5776654498198778\n",
      "Accuracy = 0.99, Loss = 0.5776021772612803\n",
      "Accuracy = 0.99, Loss = 0.5775389264474037\n",
      "Accuracy = 0.99, Loss = 0.5774756973265122\n",
      "Accuracy = 0.99, Loss = 0.5774124898472602\n",
      "Accuracy = 0.99, Loss = 0.5773493039586898\n",
      "Accuracy = 0.99, Loss = 0.5772861396102261\n",
      "Accuracy = 0.99, Loss = 0.5772229967516763\n",
      "Accuracy = 0.99, Loss = 0.577159875333224\n",
      "Accuracy = 0.99, Loss = 0.5770967753054274\n",
      "Accuracy = 0.99, Loss = 0.5770336966192159\n",
      "Accuracy = 0.99, Loss = 0.5769706392258872\n",
      "Accuracy = 0.99, Loss = 0.5769076030771039\n",
      "Accuracy = 0.99, Loss = 0.5768445881248905\n",
      "Accuracy = 0.99, Loss = 0.5767815943216305\n",
      "Accuracy = 0.99, Loss = 0.5767186216200632\n",
      "Accuracy = 0.99, Loss = 0.576655669973281\n",
      "Accuracy = 0.99, Loss = 0.5765927393347263\n",
      "Accuracy = 0.99, Loss = 0.5765298296581881\n",
      "Accuracy = 0.99, Loss = 0.5764669408977999\n",
      "Accuracy = 0.99, Loss = 0.5764040730080368\n",
      "Accuracy = 0.99, Loss = 0.5763412259437114\n",
      "Accuracy = 0.99, Loss = 0.5762783996599722\n",
      "Accuracy = 0.99, Loss = 0.576215594112301\n",
      "Accuracy = 0.99, Loss = 0.5761528092565087\n",
      "Accuracy = 0.99, Loss = 0.576090045048734\n",
      "Accuracy = 0.99, Loss = 0.5760273014454398\n",
      "Accuracy = 0.99, Loss = 0.5759645784034108\n",
      "Accuracy = 0.99, Loss = 0.5759018758797504\n",
      "Accuracy = 0.99, Loss = 0.5758391938318786\n",
      "Accuracy = 0.99, Loss = 0.5757765322175294\n",
      "Accuracy = 0.99, Loss = 0.5757138909947475\n",
      "Accuracy = 0.99, Loss = 0.5756512701218861\n",
      "Accuracy = 0.99, Loss = 0.5755886695576046\n",
      "Accuracy = 0.99, Loss = 0.5755260892608651\n",
      "Accuracy = 0.99, Loss = 0.5754635291909309\n",
      "Accuracy = 0.99, Loss = 0.5754009893073639\n",
      "Accuracy = 0.99, Loss = 0.5753384695700211\n",
      "Accuracy = 0.99, Loss = 0.5752759699390534\n",
      "Accuracy = 0.99, Loss = 0.5752134903749015\n",
      "Accuracy = 0.99, Loss = 0.5751510308382961\n",
      "Accuracy = 0.99, Loss = 0.5750885912902524\n",
      "Accuracy = 0.99, Loss = 0.5750261716920702\n",
      "Accuracy = 0.99, Loss = 0.5749637720053298\n",
      "Accuracy = 0.99, Loss = 0.574901392191891\n",
      "Accuracy = 0.99, Loss = 0.5748390322138892\n",
      "Accuracy = 0.99, Loss = 0.5747766920337355\n",
      "Accuracy = 0.99, Loss = 0.5747143716141112\n",
      "Accuracy = 0.99, Loss = 0.5746520709179687\n",
      "Accuracy = 0.99, Loss = 0.5745897899085267\n",
      "Accuracy = 0.99, Loss = 0.5745275285492699\n",
      "Accuracy = 0.99, Loss = 0.5744652868039453\n"
     ]
    }
   ],
   "source": [
    "model.fit(X.T, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.6935 - accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.6926 - accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.6916 - accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.6905 - accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.6895 - accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.6885 - accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.6875 - accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.6864 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.6853 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a1af55a0b8>"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doing with keras\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "main_input = Input(shape=(4,), name='main_input')\n",
    "hidden = Dense(32, activation=\"sigmoid\", name='hidden1')(main_input)\n",
    "hidden = Dense(64, activation=\"sigmoid\", name='hidden2')(hidden)\n",
    "hidden = Dense(32, activation=\"sigmoid\", name='hidden3')(hidden)\n",
    "out1 = Dense(1,  activation='sigmoid', name='out1')(hidden)\n",
    "model_tf = Model(inputs=main_input, outputs=[out1])\n",
    "model_tf.compile(optimizer = keras.optimizers.Adam(),loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "model_tf.fit(X, Y, batch_size=100, verbose=1, epochs=10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
